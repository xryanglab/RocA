#!/usr/bin/env python
# -*- coding:UTF-8 -*-
'''
Author: Li Fajin
Date: 2021-02-14 13:42:07
LastEditors: Li Fajin
LastEditTime: 2021-02-14 14:34:45
Description: file content
'''


import sys
import pysam
import pandas as pd
import numpy as np
from optparse import OptionParser


def create_parser_for_RPKM_calculation():
	'''argument parser.'''
	usage='usage: python %prog[options]'
	parser=OptionParser(usage=usage)
	parser.add_option("-f","--bamListFile",action="store",type="string",default=None,dest="bamListFile",
			help="Bam file list, containing 4 columns.Namely bamFiles,readLength, offSet, bamLegend. '-f' and '-i, -r, -s, -t' parameters are mutually exclusive.default=%default.")
	parser.add_option("-i","--input", action="store",type="string",dest="bam_files",
			help="Input file(s) in bam format. All files should be split by comma e.g. 1.bam,2.bam,3.bam[required]")
	parser.add_option("-c","--coordinateFile",action="store",type="string",dest="coorFile",
		help="The file should contain the coordinate of start and stop codon. Generated by OutputTranscriptInfo.py.[required]")
	parser.add_option("-o","--otput_prefix",action="store",type="string",dest="output_prefix",
			help="Prefix of output files.[required]")
	parser.add_option("-r","--specific_reads_length",action="store",type="string",dest="read_length",
			help="Specific the lenght to do analysis, comma split. e.g. '28,29,30'.If use all length set 'All'. Bam files diff length select split by '_' e.g. '28,29,30_ALL_27,28' [required]")
	parser.add_option("-s","--offset",action="store",type="string",dest="read_offset",
			help="Specific the offset corresponding to read length, comma split. e.g. '12,13,13'. No offset set 0. Bam files diff offset select split by '_' e.g. '12,13,13_0_12,12' [required]")
	parser.add_option("-t","--bam_file_legend",action="store",type="string",dest="bam_file_legend",
			help="The legend of each bam files, comma split. e.g. 'condition1,condition2,condition3' [required]")
	parser.add_option('-S','--select_trans_list',action="store",type='string',dest='in_selectTrans',
			help="Selected transcript list used for metagene analysis.This files requires the first column must be the transcript ID  with a column name.")
	parser.add_option('--id-type',action="store",type="string",dest="id_type",default="transcript_id",
		help="define the id type users input. the default is transcript id, if not, will be transformed into transcript id. %default=default")
	parser.add_option("--type",action="store",type="string",dest="Type",default='CDS',
			help="CDS or exon=%default")
	return parser

def lengths_offsets_split(value):
		''' Split the given comma separated values to multiple integer values'''
		values=[]
		for item in value.split(','):
				item=int(item)
				values.append(item)
		return values

def get_trans_frame_counts(ribo_fileobj, transcript_name, read_lengths, read_offsets, transLength, startCoor, stopCoor):
	"""For each mapped read of the given transcript in the BAM file,get the P-site and codon unit reads density
	ribo_fileobj -- file object - BAM file opened using pysam AlignmentFile
	transcript_name -- Name of transcript to get counts for
	read_length -- If provided, get counts only for reads of this length.
	read_offsets -- the offset length corresponding to 5' mapped position.
	transLength -- the length of the transcript.
	startCoor -- the coordinate of the first base of start codon 0-based.
	stopCoor -- the coordinate of the first base of stop codon 0-based.
	"""
	read_counts = np.zeros(transLength,dtype="int64")
	total_reads = 0
	if read_lengths == "ALL" : ## RNA
		for record in ribo_fileobj.fetch(transcript_name):
			if record.flag == 16 or record.flag == 272:
				continue
			total_reads += 1
			position = record.pos
			read_counts[position]+=1
	else:
		read_lengths=lengths_offsets_split(read_lengths)
		read_offsets=lengths_offsets_split(read_offsets)
		for record in ribo_fileobj.fetch(transcript_name):
			if record.flag == 16 or record.flag == 272:
				continue
			for R_length, R_offset in zip(read_lengths,read_offsets):
				if  record.query_length == R_length :
					# if an offset is specified, increment position by that offset.
					position = record.pos + R_offset ## transform into the position of P-site
				else:
					# ignore other reads/lengths
					continue
				total_reads += 1
				try:
					read_counts[position]+=1
				except KeyError:
					print("Dont has this position after offset : transcript_name -> position"+" "+transcript_name+" -> "+position)
	#get trans counts for each 3 frames
	read_counts_frame0=read_counts[(startCoor+0):(stopCoor-2):3]
	read_counts_frame1=read_counts[(startCoor+1):(stopCoor-1):3]
	read_counts_frame2=read_counts[(startCoor+2):(stopCoor-0):3]
	read_counts_frameSum=read_counts_frame0+read_counts_frame1+read_counts_frame2
	cds_reads=sum(read_counts_frameSum)
	return read_counts,read_counts_frameSum,total_reads,cds_reads

def CalculateRPKM(in_bamFile,in_bamLegend,in_selectTrans,in_transLengthDict,in_startCodonCoorDict,in_stopCodonCoorDict,in_readLengths,in_readOffset,output_prefix,Type):
	pysamFile=pysam.AlignmentFile(in_bamFile,"rb")
	pysamFile_trans=pysamFile.references
	in_selectTrans=set(pysamFile_trans).intersection(in_selectTrans)
	RPKMPerTrans={}
	all_counts=0

	for trans in in_startCodonCoorDict.keys():
		leftCoor =int(in_startCodonCoorDict[trans])-1
		rightCoor=int(in_stopCodonCoorDict[trans])-3
		(trans_counts,read_counts_frameSum,total_reads,cds_reads)=get_trans_frame_counts(pysamFile, trans, in_readLengths, in_readOffset, in_transLengthDict[trans], leftCoor, rightCoor)
		if Type.strip().upper()=="CDS":
			all_counts+=cds_reads
		elif Type.strip().upper() in ['EXON',"TRANS","TRANSCRIPT"]:
			all_counts+=total_reads
		else:
			all_counts+=total_reads ## total_reads for transcript level

	for trans in in_selectTrans:
		leftCoor =int(in_startCodonCoorDict[trans])-1 #the first base of start codon 0-base
		rightCoor=int(in_stopCodonCoorDict[trans])-3 #the first base of stop codon 0-base
		(read_counts,read_counts_frameSum,trans_reads,cds_reads)=get_trans_frame_counts(pysamFile, trans, in_readLengths, in_readOffset, in_transLengthDict[trans], leftCoor, rightCoor)
		if Type.strip().upper()=="CDS":
			counts_frame=read_counts[(leftCoor+15):(rightCoor-15)]
			length=len(counts_frame)
		elif Type.strip().upper() in ['EXON',"TRANS","TRANSCRIPT"]:
			counts_frame=read_counts
			length=len(counts_frame)
		else:
			counts_frame=read_counts
			length=len(counts_frame)
		counts_frame_sum=np.sum(counts_frame)
		if counts_frame_sum==0:
			RPKMPerTrans[trans]=0
		else:
			RPKMPerTrans[trans]=10**9*(counts_frame_sum)/(all_counts*length)
	return RPKMPerTrans

def write_bam_file_RPKM_dataframe(inBamAttr,outFile):
	data=[]
	data_index=[]
	for bms in inBamAttr:
		d=bms.RPKMPerTrans
		i=bms.bamLegend
		data.append(d)
		data_index.append(i)
	data=pd.DataFrame(data,index=data_index)
	data=data.T
	data.to_csv(outFile,sep="\t")
	return data

def reload_transcripts_information(longestTransFile):
	selectTrans=set()
	transLengthDict={}
	cdsLengthDict={}
	startCodonCoorDict={}
	stopCodonCoorDict={}
	transID2geneID={}
	transID2geneName={}
	transID2ChromDict={}
	with open(longestTransFile,'r') as f:
		for line in f:
			if line.strip()=='':
				continue
			if line.strip().split("\t")[0] == 'chrom':
				continue
			chrom=line.strip().split("\t")[0]
			transID=line.strip().split("\t")[1]
			geneID=line.strip().split("\t")[3]
			geneName=line.strip().split("\t")[4]
			startCodon=int(line.strip().split("\t")[8])
			stopCodon=int(line.strip().split("\t")[9])
			cds_length=int(line.strip().split("\t")[10])
			transLength=int(line.strip().split("\t")[13])
			selectTrans.add(transID)
			transLengthDict[transID]=transLength
			startCodonCoorDict[transID]=startCodon
			stopCodonCoorDict[transID]=stopCodon
			transID2geneID[transID]=geneID
			transID2geneName[transID]=geneName
			cdsLengthDict[transID]=cds_length
			transID2ChromDict[transID]=chrom
			# print(transID,geneID,geneName,startCodon,stopCodon,transLength)
	print(str(len(selectTrans))+'  transcripts will be used in the follow analysis.\n', file=sys.stderr)
	return selectTrans,transLengthDict,startCodonCoorDict,stopCodonCoorDict,transID2geneID,transID2geneName,cdsLengthDict,transID2ChromDict

def IDtransForm(in_selectTrans,coorFile,id_type):
	selectTrans,transLengthDict,startCodonCoorDict,stopCodonCoorDict,transID2geneID,transID2geneName,cdsLengthDict,transID2ChromDict=reload_transcripts_information(coorFile)
	geneID2transID={v:k for k,v in transID2geneID.items()}
	geneName2transID={v:k for k,v in transID2geneName.items()}
	if in_selectTrans:
		select_trans=pd.read_csv(in_selectTrans,sep="\t")
		select_trans=set(select_trans.iloc[:,0].values)
		if id_type == 'transcript_id':
			select_trans=select_trans.intersection(selectTrans)
			print("There are " + str(len(select_trans)) + " transcripts from "+in_selectTrans+" used for following analysis.",file=sys.stderr)
		elif id_type == 'gene_id':
			tmp=[geneID2transID[gene_id] for gene_id in select_trans if gene_id in geneID2transID]
			select_trans=set(tmp)
			select_trans=select_trans.intersection(selectTrans)
			print("There are " + str(len(select_trans))+" gene id could be transformed into transcript id and used for following analysis.",file=sys.stderr)
		elif id_type == 'gene_name' or id_type=='gene_symbol':
			tmp=[geneName2transID[gene_name] for gene_name in select_trans if gene_name in geneName2transID]
			select_trans=set(tmp)
			select_trans=select_trans.intersection(selectTrans)
			print("There are " + str(len(select_trans))+" gene symbol could be transformed into transcript id and used for following analysis.",file=sys.stderr)
		else:
			raise IOError("Please input a approproate id_type parameters.[transcript_id/gene_id/gene_name/]")
	else:
		select_trans=selectTrans

	return select_trans,transLengthDict,startCodonCoorDict,stopCodonCoorDict

class bam_file_attr(object):
	"""Class for bam file attribute"""
	def __init__(self,bamName,bamLen,bamOffset,bamLegend):
		self.bamName=bamName
		self.bamLen=bamLen
		self.bamOffset=bamOffset
		self.bamLegend=bamLegend

def parse_bamListFile(bamListFile):
	bamFileList=[]
	readLengthsList=[]
	OffsetsList=[]
	bamLegendsList=[]
	flag=1
	with open(bamListFile,'r') as f:
		for line in f:
			if flag == 1:
				flag+=1
				continue
			bamFile=line.strip().split("\t")[0]
			readLengths=line.strip().split("\t")[1]
			Offsets=line.strip().split("\t")[2]
			bamLegends=line.strip().split("\t")[3]
			bamFileList.append(bamFile)
			readLengthsList.append(readLengths)
			OffsetsList.append(Offsets)
			bamLegendsList.append(bamLegends)
	return bamFileList,readLengthsList,OffsetsList,bamLegendsList

def parse_args_for_RPKM_calculation():
	parsed=create_parser_for_RPKM_calculation()
	(options,args)=parsed.parse_args()
	if options.bamListFile and (options.bam_files or options.read_length or options.read_offset or options.bam_file_legend):
		raise IOError("'-f' parameter and '-i -r -s -t' are mutually exclusive.")
	if options.bamListFile:
		bamFiles,readLengths,Offsets,bamLegends=parse_bamListFile(options.bamListFile)
	elif options.bam_files:
		bamFiles,readLengths,Offsets,bamLegends=options.bam_files.split(","),options.read_length.split("_"),options.read_offset.split("_"),options.bam_file_legend.split(",")
	else:
		raise IOError("Please check you input files!")

	print("your input : "+ str(len(bamFiles))+" bam files",file=sys.stderr)
	bam_attr=[]
	for ii,jj,mm,nn in zip(bamFiles,readLengths,Offsets,bamLegends):
		bam=bam_file_attr(ii,jj,mm,nn)
		bam_attr.append(bam)
	select_trans,transLengthDict,startCodonCoorDict,stopCodonCoorDict=IDtransForm(options.in_selectTrans,options.coorFile,options.id_type)
	for bamfs in bam_attr:
		bamfs.RPKMPerTrans=CalculateRPKM(bamfs.bamName,bamfs.bamLegend,select_trans,transLengthDict,startCodonCoorDict,stopCodonCoorDict,bamfs.bamLen,bamfs.bamOffset,options.output_prefix,options.Type)
	write_bam_file_RPKM_dataframe(bam_attr,options.output_prefix+"_RPKM_dataframe.txt")


def main():
	print("Start...")
	parse_args_for_RPKM_calculation()
	print("Finish!")

if __name__=="__main__":
	main()